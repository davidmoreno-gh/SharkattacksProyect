{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas xlrd\n",
    "import pandas as pd # We import pandas to work with dataframes.\n",
    "import numpy as np # We import numpy to work with matrix.\n",
    "import xlrd # We import xlrd because pandas need it due to our original data-table is in a old version\n",
    "import re # We import regex library for searching patterns. \n",
    "\n",
    "# We load the data-table excel from the url.\n",
    "url = 'https://www.sharkattackfile.net/spreadsheets/GSAF5.xls'\n",
    "data_df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We attach to our main a python document which is keeping the main function we need to use. \n",
    "import sys\n",
    "sys.path.append(\"SHARKATTACKSPROYECT/\")\n",
    "from functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6969, 23)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are taking a snapshot about our data panel in order to see to what we are facing.\n",
    "\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems before step is enough to take a complete snapshot of our data. Lets go with another method.\n",
    "\n",
    "pd.options.display.max_columns # We get access to configure display options from Pandas and configure max columns to show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we've seen the columns distribution, we gonna face the date types of each column to know how start to work with each one.\n",
    "# We need to know how many Na/Non Values we have in data.\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YEAR AND DATE COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In column YEAR, lets see how many unique values it contains: \n",
    "data_df.Year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>Ca. 214 B.C.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>Ca. 336.B.C..</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>Ca. 493 B.C.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>Ca. 725 B.C.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>Ca. 1010  BC</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6939</th>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6940</th>\n",
       "      <td>Before 1903</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6941</th>\n",
       "      <td>1900-1905</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6942</th>\n",
       "      <td>1883-1889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6943</th>\n",
       "      <td>1845-1853</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date  Year\n",
       "6815   Ca. 214 B.C.   0.0\n",
       "6816  Ca. 336.B.C..   0.0\n",
       "6817   Ca. 493 B.C.   0.0\n",
       "6818   Ca. 725 B.C.   0.0\n",
       "6819  Ca. 1010  BC    0.0\n",
       "...             ...   ...\n",
       "6939    Before 1903   0.0\n",
       "6940    Before 1903   0.0\n",
       "6941      1900-1905   0.0\n",
       "6942      1883-1889   0.0\n",
       "6943      1845-1853   0.0\n",
       "\n",
       "[129 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are some years with no values, so we will try if we can confirm the year though column Date. \n",
    "data_df[['Date','Year']][data_df.Year == 0] #81 years we can rescue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to aply some functions in order to rescue these years:\n",
    "'''Buscamos mediante un regex, para que nos busque los años numéricos'''\n",
    "\n",
    "data_df.Date = data_df.Date.replace(regex=r'(?i)Reported\\s{1,9}',value='')\n",
    "list(data_df.Date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aunque no salen en los uniques hay muchos Dates que salen como rangos, o datos de antes de Cristo.\n",
    "# Vamos a denominarlos momentáneamente salvables para ver cuantos hay exactamente:\n",
    "salvables = data_df.loc[(data_df[\"Year\"] == 0) & (data_df[\"Date\"] != np.nan)]\n",
    "salvables.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos a las funciones definidas en el cleanin_functions.py, mas concretamente a rescatar \n",
    "# fechas que aplica 3 funciones secuencialmente donde coge por orden los que contienen BC, \n",
    "# los que son fechas sueltas (tipo Before YYYY) y luego los intervalos de los cuales saca la media, \n",
    "# para rellenar los datos de la columna Year para esos valores de Dates \n",
    "from functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Year = data_df.Date.apply(rescatar_fechas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Year=rescatar_fechas(data_df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_year = data_df.Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos todas las filas con valores NA\n",
    "\n",
    "data_df_year.dropna(axis=0, inplace= True, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_year.to_csv('datadavid1.csv', columns=['Year'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2024\n",
       "1       2024\n",
       "2       2024\n",
       "3       2024\n",
       "4       2024\n",
       "        ... \n",
       "6939    1903\n",
       "6940    1903\n",
       "6941    1900\n",
       "6942    1883\n",
       "6943    1845\n",
       "Name: Year, Length: 6925, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2024\n",
       "1       2024\n",
       "2       2024\n",
       "3       2024\n",
       "4       2024\n",
       "        ... \n",
       "6939    1903\n",
       "6940    1903\n",
       "6941    1900\n",
       "6942    1883\n",
       "6943    1845\n",
       "Name: Year, Length: 6925, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see to get a general idea about the problem with Na in order to clean approaching. We get percentages.\n",
    "\n",
    "Na_amount = round(data_df.isna().sum()*100/len(data_df), 2)\n",
    "Na_amount.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see there are some columns with a too high percentage of Nan Values.\n",
    "# A logical idea we can conclude, it is those columns with a high percentage of nan values are useless due to missinformation given.\n",
    "# So We decide to drop columns named \"Unnamed 21\" and \"Unnamed 22\".\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df.dropna(axis=0, inplace= True, thresh=int(24*0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de los datos de fecha\n",
    "\n",
    "#Columna Date\n",
    "\n",
    "#Vemos los valores únicos\n",
    "data_df.Year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos valores muy raros, como año 0, 5, 77. Por cuestiones históricas, decidimos dropear todo lo anterior al año 1800.\n",
    "\n",
    "# Como tenemos otra columna (date) que también nos da años, intentamos si podemos rescatar datos: \n",
    "\n",
    "data_df[['Date','Year']][data_df.Year == 0] #81 fechas que podemos rescatar a través de date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Date = data_df.Date.replace(regex=r'(?i)Reported\\s{1,9}',value='')\n",
    "list(data_df.Date.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.Date.str.replace(\"-\", \" \") #1\n",
    "data_df.Date.str.replace(\"_\", \" \")#2\n",
    "data_df.Date.str.strip() #3\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
